{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y31OwpktMmpy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"YellowstoneLakesData-cleaned v1 (1).xlsx\"\n",
        "output_name = \"YellowstoneLakesData-cleaned.csv\""
      ],
      "metadata": {
        "id": "fWovK5Debp1O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in Excel file\n",
        "dictionary = pd.read_excel(filepath, sheet_name=None)\n",
        "\n",
        "# Iterate through each DataFrame\n",
        "for sheet_name, df in dictionary.items():\n",
        "  # check if the first two columns are empty, then if they are drop them\n",
        "  if df.iloc[:, 0].isnull().all() and df.iloc[:, 1].isnull().all():\n",
        "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "  elif df.iloc[:, 0].isnull().all():\n",
        "    df = df.drop(df.columns[[0]], axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "  elif df.iloc[:, 1].isnull().all():\n",
        "    df = df.drop(df.columns[[1]], axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "  # Read down each column until the first value ignoring any that include the string \"this table\", then use that value as the column title.\n",
        "  for column_index in range(df.shape[1]):\n",
        "    for row_index in range(df.shape[0]):\n",
        "      if not pd.isna(df.iloc[row_index, column_index]) and \"this table\" not in str(df.iloc[row_index, column_index]):\n",
        "        df.columns.values[column_index] = df.iloc[row_index, column_index]\n",
        "        # If the row below the first value is not blank add that value to the column title\n",
        "        if not pd.isna(df.iloc[row_index+1, column_index]) and not df.iloc[row_index, column_index] == \"Site\":\n",
        "          df.columns.values[column_index] = str(df.columns.values[column_index]) + \" \" + str(df.iloc[row_index+1, column_index])\n",
        "        break\n",
        "\n",
        "  # Find the empty column dividing the two datasets and use it to break the dataframe into two seperate dataframes\n",
        "  for column_index in range(df.shape[1]):\n",
        "    if df.iloc[:, column_index].isnull().all():\n",
        "      new_df = df.iloc[:, column_index+1:].reset_index(drop=True)\n",
        "      df = df.iloc[:, :column_index].reset_index(drop=True)\n",
        "      break\n",
        "\n",
        "  # Remove unnecessary columns from the dataframes\n",
        "  # Iterate through the columns and find where there is only one value in the column or no values and drop those columns\n",
        "  df_drop = []\n",
        "  new_df_drop = []\n",
        "  for column_index in range(df.shape[1]):\n",
        "      if df.iloc[:, column_index].isnull().all() or df.iloc[:, column_index].notnull().sum() == 1:\n",
        "          df_drop.append(column_index)\n",
        "  for column_index in range(new_df.shape[1]):\n",
        "      if new_df.iloc[:, column_index].isnull().all() or new_df.iloc[:, column_index].notnull().sum() == 1:\n",
        "          new_df_drop.append(column_index)\n",
        "  # Drop the unnecessary columns\n",
        "  df = df.drop(df.columns[df_drop], axis=1)\n",
        "  new_df = new_df.drop(new_df.columns[new_df_drop], axis=1)\n",
        "\n",
        "  # Remove all unecessary rows from the dataframes using the site column\n",
        "  df = df[df[\"Site\"].notna() & (df[\"Site\"] != \"Site\")].reset_index(drop=True)\n",
        "  df[\"df_name\"] = sheet_name\n",
        "  new_df = new_df[new_df[\"Site\"].notna() & (new_df[\"Site\"] != \"Site\")].reset_index(drop=True)\n",
        "  new_df[\"df_name\"] = sheet_name + \"2\"\n",
        "\n",
        "  # Add new_df to the bottom of df\n",
        "  df = pd.concat([df, new_df], ignore_index=True)\n",
        "  dictionary[sheet_name] = df\n",
        "\n",
        "# Combine the dataframes and output a csv of the data\n",
        "combine = pd.concat(dictionary.values(), ignore_index=True)\n",
        "combine.to_csv(output_name, index=False)\n",
        "print(f\"Data saved to the Colab file explorer as {output_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihcoSdIRgJuR",
        "outputId": "d5118bb0-9bee-43cb-e7bf-f4e455a5d067"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to the Colab file explorer as YellowstoneLakesData-cleaned.csv\n"
          ]
        }
      ]
    }
  ]
}