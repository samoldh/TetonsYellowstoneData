{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y31OwpktMmpy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"TetonLakesDataOrig2.xlsx\"\n",
        "output_name = \"TetonsLakesData.csv\"\n",
        "national_park = \"Grand Tetons\""
      ],
      "metadata": {
        "id": "fWovK5Debp1O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in Excel file\n",
        "dictionary = pd.read_excel(filepath, sheet_name=None)\n",
        "\n",
        "# Iterate through each DataFrame\n",
        "print(\"Processed Sheets:\")\n",
        "for sheet_name, df in dictionary.items():\n",
        "  # check if the first two columns are empty, then if they are drop them\n",
        "  if df.iloc[:, 0].isnull().all() and df.iloc[:, 1].isnull().all():\n",
        "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "  elif df.iloc[:, 0].isnull().all():\n",
        "    df = df.drop(df.columns[[0]], axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "  elif df.iloc[:, 1].isnull().all():\n",
        "    df = df.drop(df.columns[[1]], axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "  # Read down each column until the first value ignoring any that include the string \"this table\", then use that value as the column title.\n",
        "  for column_index in range(df.shape[1]):\n",
        "    for row_index in range(df.shape[0]):\n",
        "      if not pd.isna(df.iloc[row_index, column_index]) and \"this table\" not in str(df.iloc[row_index, column_index]):\n",
        "        df.columns.values[column_index] = df.iloc[row_index, column_index]\n",
        "        # If the row below the first value is not blank add that value to the column title\n",
        "        if not pd.isna(df.iloc[row_index+1, column_index]) and not df.iloc[row_index, column_index] == \"Site\":\n",
        "          df.columns.values[column_index] = str(df.columns.values[column_index]) + \" \" + str(df.iloc[row_index+1, column_index])\n",
        "        break\n",
        "  # Filter the dataframe and for any cells that say no data replace that with a null value\n",
        "  df = df.replace(\"no data\", pd.NA)\n",
        "  df = df.replace(\"not yet\", pd.NA)\n",
        "\n",
        "  # Use the Location column in df to make a new column called Location_note which is anything after Inlake or Inlet, then remove any characters after the words Inlake or Inlet in the Location column\n",
        "  df[\"Location\"] = df[\"Location\"].str.replace(\"inlet\", \"Inlet\")\n",
        "  df[\"Location\"] = df[\"Location\"].str.replace(\"inlake\", \"Inlake\")\n",
        "  df[\"Location\"] = df[\"Location\"].str.replace(\"outlet\", \"Outlet\")\n",
        "  df[\"Location_note\"] = df[\"Location\"].str.replace(\"Inlake\", \"\").str.replace(\"Inlet\", \"\").str.replace(\" \", \"\").str.replace(\"Outlet\", \"\")\n",
        "  df[\"Location\"] = df[\"Location\"].astype(str).apply(lambda x: \"Inlake\" if \"Inlake\" in x else x)\n",
        "  df[\"Location\"] = df[\"Location\"].astype(str).apply(lambda x: \"Inlet\" if \"Inlet\" in x else x)\n",
        "  df[\"Location\"] = df[\"Location\"].astype(str).apply(lambda x: \"Outlet\" if \"Outlet\" in x else x)\n",
        "\n",
        "  # Remove unnecessary columns from the dataframes\n",
        "  # Iterate through the columns and find where there is only one value in the column or no values and drop those columns\n",
        "  df_drop = []\n",
        "  for column_index in range(df.shape[1]):\n",
        "      if df.iloc[:, column_index].isnull().all() or df.iloc[:, column_index].notnull().sum() == 1:\n",
        "          df_drop.append(column_index)\n",
        "\n",
        "  # Drop the unnecessary columns\n",
        "  df = df.drop(df.columns[df_drop], axis=1)\n",
        "\n",
        "  # Remove all unecessary rows from the dataframes using the location column\n",
        "  df = df[df[\"Location\"].notna() & (df[\"Location\"] != \"Location\")].reset_index(drop=True)\n",
        "\n",
        "  # Take the Year and Month columns and make a new column called Date which has both of them in a datetime format\n",
        "  df = df[df[\"Month\"].notna() & (df[\"Month\"] != \"no data\")].reset_index(drop=True)\n",
        "  print(sheet_name)\n",
        "  df[\"Date\"] = pd.to_datetime(df[\"Year\"].astype(str) + \"-\" + df[\"Month\"].astype(str), format=\"%Y-%b\")\n",
        "\n",
        "  # Add new columns\n",
        "  df[\"df_name\"] = sheet_name\n",
        "  df[\"Side\"] = 3\n",
        "\n",
        "  # Add df to the dictionary\n",
        "  dictionary[sheet_name] = df\n",
        "\n",
        "# Combine the dataframes and output a csv of the data\n",
        "combine = pd.concat(dictionary.values(), ignore_index=True)\n",
        "combine[\"National Park\"] = national_park\n",
        "combine.to_csv(output_name, index=False)\n",
        "print(f\"Data saved to the Colab file explorer as {output_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihcoSdIRgJuR",
        "outputId": "ab02a9df-e694-4f2d-9055-278b6baafeea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sheets:\n",
            "Two Ocean\n",
            "Moose Pond\n",
            "Swan Lake\n",
            "StringLake\n",
            "EmmaMatilda\n",
            "TaggartLake\n",
            "ChristianPond\n",
            "CygnetPond\n",
            "BradleyLake\n",
            "PhelpsLake\n",
            "OxbowBend\n",
            "ColterBay\n",
            "DeltaLake\n",
            "Bays\n",
            "OneTimeLakes\n",
            "LeighLake\n",
            "JennyLake\n",
            "SurpriseLake\n",
            "AmphitheaterLake\n",
            "LakeSolitude\n",
            "Data saved to the Colab file explorer as TetonsLakesData.csv\n"
          ]
        }
      ]
    }
  ]
}